{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The purpose of this anlaysis is trying to find out the products that are purchased most in the HappyDB dataset.**  \n",
    "These products are more likely to make people feel happy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I'll use KOKO, a rule-based entity extraction system, to perform the analysis.**  \n",
    "\n",
    "KOKO allows users to specify conditions of desirable entities with a declarative language (see [KOKO syntax](#koko_syntax)).  \n",
    "Those entities that obtain scores higher than a threshold are extracted.\n",
    "\n",
    "KOKO is especially suitable for entity extraction with limited evidence in the corpus (e.g. extraction of cafe names within only one or a few blogs). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The whole analysis described in this notebook comprises the following steps:**  \n",
    "\n",
    "- Data preprocessing: load HappyDB dataset and convert it to a text file as input to KOKO.\n",
    "- KOKO introduction: briefly introduce the syntax and semantics of KOKO, with an example query.\n",
    "- Entity extraction: a KOKO query is written and evaluated, extracting product names in the dataset.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the data and take a look at the happy moments.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load HappyDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1.1</th>\n",
       "      <th>hmid</th>\n",
       "      <th>wid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>original_hm</th>\n",
       "      <th>modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3833.0</td>\n",
       "      <td>31526.0</td>\n",
       "      <td>8962.0</td>\n",
       "      <td>24h</td>\n",
       "      <td>I found a silver coin from 1852 buried in the ...</td>\n",
       "      <td>I found a silver coin from 1852 buried in the ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9336.0</td>\n",
       "      <td>37050.0</td>\n",
       "      <td>10252.0</td>\n",
       "      <td>24h</td>\n",
       "      <td>This one is pretty minuscule, we had to go to ...</td>\n",
       "      <td>This one is pretty minuscule, we had to go to ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18454.0</td>\n",
       "      <td>46196.0</td>\n",
       "      <td>586.0</td>\n",
       "      <td>24h</td>\n",
       "      <td>The word problem is never part of a happy pers...</td>\n",
       "      <td>The word aproblema is never part of a happy pe...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>22355.0</td>\n",
       "      <td>50108.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>24h</td>\n",
       "      <td>I started  studying  bagavthgeetha .</td>\n",
       "      <td>I started  studying  bagavthgeetha .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>27323.0</td>\n",
       "      <td>55093.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>24h</td>\n",
       "      <td>i go to old age home and service enjoy the mom...</td>\n",
       "      <td>i go to oldage home and service enjoy the moment.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1.1.1     hmid  \\\n",
       "0           0             0               0                3833.0  31526.0   \n",
       "1           1             1               1                9336.0  37050.0   \n",
       "2           2             2               2               18454.0  46196.0   \n",
       "3           3             3               3               22355.0  50108.0   \n",
       "4           4             4               4               27323.0  55093.0   \n",
       "\n",
       "       wid reflection_period  \\\n",
       "0   8962.0               24h   \n",
       "1  10252.0               24h   \n",
       "2    586.0               24h   \n",
       "3    409.0               24h   \n",
       "4    731.0               24h   \n",
       "\n",
       "                                          cleaned_hm  \\\n",
       "0  I found a silver coin from 1852 buried in the ...   \n",
       "1  This one is pretty minuscule, we had to go to ...   \n",
       "2  The word problem is never part of a happy pers...   \n",
       "3               I started  studying  bagavthgeetha .   \n",
       "4  i go to old age home and service enjoy the mom...   \n",
       "\n",
       "                                         original_hm  modified  \n",
       "0  I found a silver coin from 1852 buried in the ...     False  \n",
       "1  This one is pretty minuscule, we had to go to ...     False  \n",
       "2  The word aproblema is never part of a happy pe...     False  \n",
       "3               I started  studying  bagavthgeetha .      True  \n",
       "4  i go to oldage home and service enjoy the moment.     False  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./cleaned_hm.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the dataset, the most interesting part -- which is also the input to our analysis -- is the coloum of 'cleaned_hm'.  \n",
    "\n",
    "'cleaned_hm' stands for \"cleaned happy moments\". Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I found a silver coin from 1852 buried in the sand of CapAo da Canoa beach, located in southern Brazil.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "1    This one is pretty minuscule, we had to go to the laundromat today and obviously I had all three of my kids with me, my 5 year old, my 2 year old and my 5 month old. Last time we had to go they were all butts, my 5 month old wanted to scream the whole time and my two girls were all over the place. Today they were basically perfect, my 5 month old stayed content in his car seat with his toys and I tried to make it more fun for my girls so after getting the clothes in the dryer we went and got drinks and they just sat patiently waiting with minimal outbursts. It was nice to get laundry done in some peace and I really appreciated the fact that some part of them realized that this needed to get done. \n",
       "2    The word problem is never part of a happy personas vocabulary. A problem is viewed as a drawback, a struggle, or an unstable situation while a challenge is viewed as something positive like an opportunity, a task, or a dare. Whenever you face an obstacle, try looking at it as a challenge.                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "3    I started  studying  bagavthgeetha .                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "4    i go to old age home and service enjoy the moment.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "Name: cleaned_hm, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "data_clean = data['cleaned_hm']\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify purchasing-related moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Python to take a peek at all the happy moments related to purchasing behavior -- \n",
    "i.e., moments that contain keywords 'buy', 'bought' or 'purchase'.  \n",
    "\n",
    "This process could help us understand the patterns of products appearing in the happy moments, and faciliate condition specification in latter steps when we use KOKO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy moments involving purchasing:\n",
      "\n",
      "38: I waited patiantly for my income tax return and finally received it. And no i haven't went rogue with impulse purchases. I just did  the noble thing to do and take care of home, made a couple of investments and put the rest in my bank account.\n",
      "45: I am happy when i purchase a new vehicle \n",
      "94: My husband purchased a new nan for me.\n"
     ]
    }
   ],
   "source": [
    "num_moments = 100\n",
    "assert (num_moments < data_clean.size)\n",
    "print('Happy moments involving purchasing:\\n')\n",
    "for i in range(0, num_moments):\n",
    "    if 'buy' in data_clean.iloc[i] or \\\n",
    "       'bought' in data_clean.iloc[i] or \\\n",
    "       'purchase' in data_clean.iloc[i]:\n",
    "       print(\"{}: {}\".format(i, data_clean.iloc[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='koko_syntax'></a>\n",
    "# 2. Introduction to KOKO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using KOKO to extract products from HappyDB, I'll give a brief introduction of KOKO's query language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here's am example query *Q_prod* that I'll use to extract products.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract \"Ngrams(1,1)\" x from \"./happydb.txt\" if\n",
      "\t\t   (\"bought a new\" x {0.01}) or\n",
      "\t\t   (\"bought a few\" x {0.01}) or\n",
      "\t\t   (\"bought some\" x {0.01}) or\n",
      "\t\t   (\"bought a\" x {0.01}) or\n",
      "\t\t   (x \"I bought\" {0.01}) or\t\t   \n",
      "\t\t   (\"purchased a new\" x {0.01}) or\n",
      "\t\t   (\"purchased a few\" x {0.01}) or\n",
      "\t\t   (\"purchased some\" x {0.01}) or\n",
      "\t\t   (\"purchased a\" x {0.01}) or\n",
      "\t\t   (x \"I purchased\" {0.01})\n",
      "with threshold 0.2\n",
      "excluding (str(x) matches \".*(new|NEW|few).*\")\n",
      "excluding (str(x) matches \".*(,|\\.|;|!|\\$|\\(|\\)|-).*\")\n",
      "excluding (str(x) matches \".*[0-9]+.*\")\n",
      "excluding (str(x) matches \".*(and|or|so|the|this|that).*\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./products.koko', 'r') as query:\n",
    "    print(query.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand *Q_prod*, let's take a look at the syntax of KOKO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='koko_syntax'></a>\n",
    "## KOKO syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**extract** ⟨keyword⟩ x **from** ⟨document name⟩ **if**  \n",
    "⟨condition⟩  \n",
    "(**with threshold** ⟨threshold⟩)  \n",
    "[**excluding** ⟨e-condition⟩]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the conditions are defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*⟨condition⟩ ::= ⟨condition⟩ or ⟨condition⟩ |*  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "              *(x {⟨string⟩} ⟨weight⟩) |*  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "              *(x ⟨string⟩ ⟨weight⟩) |*  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "              *(x near ⟨string⟩ ⟨weight⟩) |*  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "              *(str(x) matches⟨pattern⟩) |*  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "              *(str(x) [contains|mentions] {⟨string⟩} ⟨weight⟩) |*  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "              *(str(x) [contains|mentions] ⟨string⟩ ⟨weight⟩)*\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  \n",
    "*⟨weight⟩ ::= empty | number in [0,1]*\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  \n",
    "*⟨threshold⟩ ::= number in [0,1]*\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  \n",
    "*⟨pattern⟩::= ⟨regular expression⟩*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, a KOKO query will extract entities *x* of type ⟨keyword⟩ from a document ⟨document name⟩, \n",
    "if the score of *x* exceeds the treshold ⟨threshold⟩.  \n",
    "\n",
    "The score is computed as the cumulative weights of conditions that are satisfied by *x* in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Let's use the query *Q_prod* presented above as an example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In *Q_prod*, the ⟨keyword⟩ is \"Ngrams(1,1)\", which means all the one-gram in the document.  \n",
    "We can also use \"Ents\" for named entities, or \"Nps\" for noun phrases.  \n",
    "\n",
    "There are twelve conditions in ⟨condition⟩. For example, (\"bought a new\" x {0.01}) means that an entity *x* with a preceding string of \"bought a new\" will have its score increased by 0.01 -- i.e., the weight of the condition.  \n",
    "\n",
    "And the first \"excluding\" keyword specifies that the matching entities should not be any word containing \"new\", \"NEW\", or \"few\" -- we are more interested in \"car\", for instance, than \"a new car\" or \"a few cars\".  \n",
    "Other \"excluding\" conditions have a similar role."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Entity extraction with KOKO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to run the query for product extraction.  \n",
    "\n",
    "First, we need to install the KOKO package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install KOKO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install KOKO locally, simply run the following command:\n",
    "\n",
    "    pip install pykoko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate plain-text happy moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KOKO queries take texts as input. Let's generate plain-text happy moments for query evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain-text happy moments are generated!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Read the happyDB sample file\n",
    "with open('./happydb.txt', 'w') as ofile:\n",
    "    for i in range(0, data['cleaned_hm'].size-1):    \n",
    "        ofile.write(\"\\t\" + data['cleaned_hm'].iloc[i] + '\\n')\n",
    "        \n",
    "print(\"Plain-text happy moments are generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run KOKO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After KOKO is installed, we can run the example query *Q_prod*.  \n",
    "\n",
    "Considering the size of the dataset, it might take several minutes to get results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed query: extract \"/Users/chen/Research/Playground/Github_Playground/happydb/data/happyDB_clean.txt\" Ngrams(1,1) from \"x\" if\n",
      "\t(\"bought a new\" x { 0.01 }) or\n",
      "\t(\"bought a few\" x { 0.01 }) or\n",
      "\t(\"bought some\" x { 0.01 }) or\n",
      "\t(\"bought a\" x { 0.01 }) or\n",
      "\t(x \"I bought\" { 0.01 }) or\n",
      "\t(\"purchased a new\" x { 0.01 }) or\n",
      "\t(\"purchased a few\" x { 0.01 }) or\n",
      "\t(\"purchased some\" x { 0.01 }) or\n",
      "\t(\"purchased a\" x { 0.01 }) or\n",
      "\t(x \"I purchased\" { 0.01 })   \n",
      "with threshold 0.20\n",
      "excluding\n",
      "\t(str(x) matches \".*(new|NEW|few).*\")\n",
      "\t(str(x) matches \".*(,|\\.|;|!|\\$|\\(|\\)|-).*\")\n",
      "\t(str(x) matches \".*[0-9]+.*\")\n",
      "\t(str(x) matches \".*(and|or|so|the|this|that).*\")\n",
      "\n",
      "\n",
      "Results:\n",
      "\n",
      "Entity name                                        Entity score\n",
      "===============================================================\n",
      "car                                                1.000000\n",
      "When                                               1.000000\n",
      "pair                                               0.470000\n",
      "house                                              0.440000\n",
      "laptop                                             0.420000\n",
      "bike                                               0.360000\n",
      "smartphone                                         0.330000\n",
      "video                                              0.320000\n",
      "month                                              0.310000\n",
      "yesterday                                          0.310000\n",
      "Computer                                           0.280000\n",
      "phone                                              0.240000\n",
      "dress                                              0.240000\n",
      "Bicycle                                            0.240000\n",
      "home                                               0.230000\n",
      "day                                                0.230000\n",
      "TV                                                 0.230000\n",
      "game                                               0.210000\n",
      "nice                                               0.210000\n",
      "Air                                                0.200000\n"
     ]
    }
   ],
   "source": [
    "import koko\n",
    "\n",
    "koko.run('./products.koko')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results contain certain noise, such as \"When\", \"pair\". But most entries are relevant.\n",
    "\n",
    "**It seems that expensive purchase, such as cars, houses or laptops, are mentioned most in HappyDB.**  \n",
    "\n",
    "Well, this makes sense. Expensive purchase is often for products people long for but could only afford after saving money for an extended period of time.  \n",
    "No wonder such purchase makes people happy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use spaCy or Google NLP for document parsing, instead of KOKO's default parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here's an example of using spaCy as the parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 2017-09-22 15:15:48,160 - Loading SpaCy English models\n",
      "INFO 2017-09-22 15:15:48,160 - Loading SpaCy English models\n",
      "INFO 2017-09-22 15:15:48,160 - Loading SpaCy English models\n",
      "INFO 2017-09-22 15:15:48,160 - Loading SpaCy English models\n",
      "INFO 2017-09-22 15:15:50,853 - Done\n",
      "INFO 2017-09-22 15:15:50,853 - Done\n",
      "INFO 2017-09-22 15:15:50,853 - Done\n",
      "INFO 2017-09-22 15:15:50,853 - Done\n",
      "Parsed query: extract \"/Users/chen/Research/Playground/Github_Playground/happydb/data/happyDB_clean.txt\" Ngrams(1,1) from \"x\" if\n",
      "\t(\"bought a new\" x { 0.01 }) or\n",
      "\t(\"bought a few\" x { 0.01 }) or\n",
      "\t(\"bought some\" x { 0.01 }) or\n",
      "\t(\"bought a\" x { 0.01 }) or\n",
      "\t(x \"I bought\" { 0.01 }) or\n",
      "\t(\"purchased a new\" x { 0.01 }) or\n",
      "\t(\"purchased a few\" x { 0.01 }) or\n",
      "\t(\"purchased some\" x { 0.01 }) or\n",
      "\t(\"purchased a\" x { 0.01 }) or\n",
      "\t(x \"I purchased\" { 0.01 })   \n",
      "with threshold 0.20\n",
      "excluding\n",
      "\t(str(x) matches \".*(new|NEW|few).*\")\n",
      "\t(str(x) matches \".*(,|\\.|;|!|\\$|\\(|\\)|-).*\")\n",
      "\t(str(x) matches \".*[0-9]+.*\")\n",
      "\t(str(x) matches \".*(and|or|so|the|this|that).*\")\n",
      "\n",
      "\n",
      "Results:\n",
      "\n",
      "Entity name                                        Entity score\n",
      "===============================================================\n",
      "                                                   1.000000\n",
      "car                                                1.000000\n",
      "When                                               1.000000\n",
      "pair                                               0.470000\n",
      "house                                              0.430000\n",
      "laptop                                             0.420000\n",
      "bike                                               0.360000\n",
      "smartphone                                         0.330000\n",
      "video                                              0.320000\n",
      "yesterday                                          0.310000\n",
      "month                                              0.290000\n",
      "Computer                                           0.280000\n",
      "phone                                              0.240000\n",
      "dress                                              0.240000\n",
      "Bicycle                                            0.240000\n",
      "home                                               0.220000\n",
      "nice                                               0.210000\n",
      "Air                                                0.200000\n",
      "game                                               0.200000\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "koko.run('./products.koko', doc_parser='spacy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are slightly different. But the entities extracted are identical except \"TV\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a quick and preliminary analysis of the HappyDB dataset. In the analysis:\n",
    "\n",
    "- I tried to extract the products that tend to make people happy.\n",
    "\n",
    "- I introduced KOKO, an entity extraction system with a declarative rule-based specification language.\n",
    "\n",
    "- I showed how to write KOKO queries to concisely specify desirable entities, and use KOKO runtime to extract these entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
